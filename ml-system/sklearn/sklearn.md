<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Getting started](#getting-started)
- [Algorithms](#algorithms)
  - [Naive Bayes f](#naive-bayes-f)
  - [Support Vector Machine (SVM)](#support-vector-machine-svm)
  - [Decision Tree](#decision-tree)
  - [K Nearest Neighbors](#k-nearest-neighbors)
  - [Random Forest](#random-forest)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# Getting started

The algorithms here are experiments from [this tutorial series](https://medium.com/machine-learning-101/chapter-0-what-is-machine-learning-ad136361c618).

- Install python
- Install pip
- Install sklearn for python : pip install scikit-learn
- Install numpy: pip install numpy
- Install SciPy: pip install scipy

```
python {algothrim}.py
```

# Algorithms

Code and dataset from: https://github.com/savanpatel/machine-learning-101. Note algorithms here are
not limited to classification problem: they can also apply to regression problem, e.g. random forest
can be used for classification, regression and other tasks. Links and code here only deal with
classification ones.

## Naive Bayes

Readings
- [naive bayes theory](https://medium.com/machine-learning-101/chapter-1-supervised-learning-and-naive-bayes-classification-part-1-theory-8b9e361897d5)
- [naive bayes coding](https://medium.com/machine-learning-101/chapter-1-supervised-learning-and-naive-bayes-classification-part-2-coding-5966f25f1475)

## Support Vector Machine (SVM)

Readings
- [support vector machine](https://www.jeremyjordan.me/support-vector-machines/)
- [support vector machine tutorial](https://blog.statsbot.co/support-vector-machines-tutorial-c1618e635e93)
- [support vector machine theory](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)
- [support vector machine coding](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-coding-edd8f1cf8f2d)

## Decision Tree

Readings
- [decision tree](https://www.jeremyjordan.me/decision-trees-for-classification/)
- [decision tree theory](https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567)
- [decision tree coding](https://medium.com/machine-learning-101/chapter-3-decision-tree-classifier-coding-ae7df4284e99)

## K Nearest Neighbors

Readings
- [quick introduction](https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7)
- [k nearest neighbors](https://www.jeremyjordan.me/k-nearest-neighbors/)
- [k nearest neighbors theory](https://medium.com/machine-learning-101/k-nearest-neighbors-classifier-1c1ff404d265)

## Random Forest

Readings
- [how random forest works](https://medium.com/@Synced/how-random-forest-algorithm-works-in-machine-learning-3c0fe15b6674)
- [random forest theory](https://medium.com/machine-learning-101/chapter-5-random-forest-classifier-56dc7425c3e1)
