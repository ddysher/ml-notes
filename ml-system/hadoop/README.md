# Hadoop

Currently, **four core modules** are included in Hadoop
- Hadoop Common: the libraries and utilities used by other Hadoop modules.
- Hadoop Distributed File System (HDFS): the Java-based scalable storage system.
- YARN: (Yet Another Resource Negotiator) provides resource management for processes running on Hadoop.
- MapReduce: a parallel processing software framework.

Other software components that can run on top of or alongside Hadoop:
- Ambari: A web interface for managing, configuring and testing Hadoop services and components.
- Cassandra: A distributed database system.
- Flume: Software that collects, aggregates and moves large amounts of streaming data into HDFS.
- HBase: A nonrelational, distributed database that runs on top of Hadoop.
- HCatalog: A table and storage management layer that helps users share and access data.
- Hive: A data warehousing and SQL-like query language that presents data in the form of tables.
- Oozie: A Hadoop job scheduler.
- Pig: A platform for manipulating data stored in HDFS.
- Solr: A scalable search tool that includes indexing, reliability, central configuration, failover and recovery.
- Spark: An open-source cluster computing framework with in-memory analytics.
- Sqoop: A connection and transfer mechanism that moves data between Hadoop and relational databases.
- Zookeeper: An application that coordinates distributed processing.

*References*

- https://www.sas.com/en_us/insights/big-data/hadoop.html
