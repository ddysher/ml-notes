{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://fairyonice.github.io/Learn-about-Fully-Convolutional-Networks-for-semantic-segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"dataset1/\"\n",
    "dir_seg = dir_data + \"/annotations_prepped_train/\"\n",
    "dir_img = dir_data + \"/images_prepped_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## seaborn has white grid by default so I will get rid of this.\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "\n",
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "## pick the first image file\n",
    "fnm = ldseg[0]\n",
    "print(fnm)\n",
    "\n",
    "## read in the original image and segmentation labels\n",
    "seg = cv2.imread(dir_seg + fnm ) # (360, 480, 3)\n",
    "img_is = cv2.imread(dir_img + fnm )\n",
    "print(\"seg.shape={}, img_is.shape={}\".format(seg.shape,img_is.shape))\n",
    "\n",
    "## Check the number of labels\n",
    "mi, ma = np.min(seg), np.max(seg)\n",
    "n_classes = ma - mi + 1\n",
    "print(\"minimum seg = {}, maximum seg = {}, Total number of segmentation classes = {}\".format(mi,ma, n_classes))\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(img_is)\n",
    "ax.set_title(\"original image\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for k in range(mi,ma+1):\n",
    "    ax = fig.add_subplot(3,n_classes/3,k+1)\n",
    "    ax.imshow((seg == k)*1.0)\n",
    "    ax.set_title(\"label = {}\".format(k))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def give_color_to_seg_img(seg,n_classes):\n",
    "    '''\n",
    "    seg : (input_width,input_height,3)\n",
    "    '''\n",
    "    \n",
    "    if len(seg.shape)==3:\n",
    "        seg = seg[:,:,0]\n",
    "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
    "    colors = sns.color_palette(\"hls\", n_classes)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        segc = (seg == c)\n",
    "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
    "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
    "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
    "\n",
    "    return(seg_img)\n",
    "\n",
    "input_height , input_width = 224 , 224\n",
    "output_height , output_width = 224 , 224\n",
    "\n",
    "\n",
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "for fnm in ldseg[np.random.choice(len(ldseg),3,replace=False)]:\n",
    "    fnm = fnm.split(\".\")[0]\n",
    "    seg = cv2.imread(dir_seg + fnm + \".png\") # (360, 480, 3)\n",
    "    img_is = cv2.imread(dir_img + fnm + \".png\")\n",
    "    seg_img = give_color_to_seg_img(seg,n_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    ax.imshow(seg_img)\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original image {}\".format(img_is.shape[:2]))\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    ax.imshow(cv2.resize(seg_img,(input_height , input_width)))\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    ax.imshow(cv2.resize(img_is,(output_height , output_width))/255.0)\n",
    "    ax.set_title(\"resized to {}\".format((output_height , output_width)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageArr( path , width , height ):\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = cv2.resize(img, ( width , height ))\n",
    "    img = img[:, : , 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "    ##seg_labels = np.reshape(seg_labels, ( width*height,nClasses  ))\n",
    "    return seg_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = os.listdir(dir_img)\n",
    "images.sort()\n",
    "segmentations  = os.listdir(dir_seg)\n",
    "segmentations.sort()\n",
    "    \n",
    "X = []\n",
    "Y = []\n",
    "for im , seg in zip(images,segmentations) :\n",
    "    X.append( getImageArr(dir_img + im , input_width , input_height )  )\n",
    "    Y.append( getSegmentationArr( dir_seg + seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "X, Y = np.array(X) , np.array(Y)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import usual libraries\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import pandas as pd \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"2\" \n",
    "set_session(tf.Session(config=config))   \n",
    "\n",
    "print(\"python {}\".format(sys.version))\n",
    "print(\"keras version {}\".format(keras.__version__)); del keras\n",
    "print(\"tensorflow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## location of VGG weights\n",
    "VGG_Weights_path = \"./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN8( nClasses ,  input_height=224, input_width=224):\n",
    "    ## input_height and width must be devisible by 32 because maxpooling with filter size = (2,2) is operated 5 times,\n",
    "    ## which makes the input_height and width 2^5 = 32 times smaller\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "    IMAGE_ORDERING =  \"channels_last\" \n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width, 3)) ## Assume 224,224,3\n",
    "    \n",
    "    ## Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    pool3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)## (None, 14, 14, 512) \n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(pool4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)## (None, 7, 7, 512)\n",
    "\n",
    "    #x = Flatten(name='flatten')(x)\n",
    "    #x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    # <--> o = ( Conv2D( 4096 , ( 7 , 7 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)\n",
    "    # assuming that the input_height = input_width = 224 as in VGG data\n",
    "    \n",
    "    #x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    # <--> o = ( Conv2D( 4096 , ( 1 , 1 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)   \n",
    "    # assuming that the input_height = input_width = 224 as in VGG data\n",
    "    \n",
    "    #x = Dense(1000 , activation='softmax', name='predictions')(x)\n",
    "    # <--> o = ( Conv2D( nClasses ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o)\n",
    "    # assuming that the input_height = input_width = 224 as in VGG data\n",
    "    \n",
    "    \n",
    "    vgg  = Model(  img_input , pool5  )\n",
    "    vgg.load_weights(VGG_Weights_path) ## loading VGG weights for the encoder parts of FCN8\n",
    "    \n",
    "    n = 4096\n",
    "    o = ( Conv2D( n , ( 7 , 7 ) , activation='relu' , padding='same', name=\"conv6\", data_format=IMAGE_ORDERING))(pool5)\n",
    "    conv7 = ( Conv2D( n , ( 1 , 1 ) , activation='relu' , padding='same', name=\"conv7\", data_format=IMAGE_ORDERING))(o)\n",
    "    \n",
    "    \n",
    "    ## 4 times upsamping for pool4 layer\n",
    "    conv7_4 = Conv2DTranspose( nClasses , kernel_size=(4,4) ,  strides=(4,4) , use_bias=False, data_format=IMAGE_ORDERING )(conv7)\n",
    "    ## (None, 224, 224, 10)\n",
    "    ## 2 times upsampling for pool411\n",
    "    pool411 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool4_11\", data_format=IMAGE_ORDERING))(pool4)\n",
    "    pool411_2 = (Conv2DTranspose( nClasses , kernel_size=(2,2) ,  strides=(2,2) , use_bias=False, data_format=IMAGE_ORDERING ))(pool411)\n",
    "    \n",
    "    pool311 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool3_11\", data_format=IMAGE_ORDERING))(pool3)\n",
    "        \n",
    "    o = Add(name=\"add\")([pool411_2, pool311, conv7_4 ])\n",
    "    o = Conv2DTranspose( nClasses , kernel_size=(8,8) ,  strides=(8,8) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    \n",
    "    model = Model(img_input, o)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = FCN8(nClasses     = n_classes,  \n",
    "             input_height = 224, \n",
    "             input_width  = 224)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_rate = 0.85\n",
    "index_train = np.random.choice(X.shape[0],int(X.shape[0]*train_rate),replace=False)\n",
    "index_test  = list(set(range(X.shape[0])) - set(index_train))\n",
    "                            \n",
    "X, Y = shuffle(X,Y)\n",
    "X_train, y_train = X[index_train],Y[index_train]\n",
    "X_test, y_test = X[index_test],Y[index_test]\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sgd = optimizers.SGD(lr=1E-2, decay=5**(-4), momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist1 = model.fit(X_train,y_train,\n",
    "                  validation_data=(X_test,y_test),\n",
    "                  batch_size=32,epochs=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['loss', 'val_loss']:\n",
    "    plt.plot(hist1.history[key],label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
    "        IoUs.append(IoU)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
    "    \n",
    "IoU(y_testi,y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (224,224)\n",
    "n_classes= 10\n",
    "\n",
    "for i in range(10):\n",
    "    img_is  = (X_test[i] + 1)*(255.0/2)\n",
    "    seg = y_predi[i]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,30))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(give_color_to_seg_img(seg,n_classes))\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(give_color_to_seg_img(segtest,n_classes))\n",
    "    ax.set_title(\"true class\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
